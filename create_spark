%jdbc(hive) show tables

Ustanowienie nowej sesji:
%spark2
val hiveContext = new org.apache.spark.sql.SparkSession.Builder().getOrCreate()

PRZEGLĄDANIE LISTY TABEL Z HURTOWNI HIVE
%spark2
hiveContext.sql("show tables").show()

Przygotowane:
%spark2
val geolocation_temp1 = hiveContext.sql("select * from geolocation")

%spark2
val drivermileage_temp1 = hiveContext.sql("select * from drivermileage")

%spark2
geolocation_temp1.createOrReplaceTempView("geolocation_temp1")
drivermileage_temp1.createOrReplaceTempView("drivermileage_temp1")
hiveContext.sql("show tables").show()

%spark2
val geolocation_temp2 = hiveContext.sql("SELECT driverid, count(driverid) occurance from geolocation_temp1 where event!='normal' group by driverid")

%spark2
geolocation_temp2.createOrReplaceTempView("geolocation_temp2")
hiveContext.sql("show tables").show()

WYKONANIE OPERACJI ZŁĄCZENIA:
%spark2
val joined = hiveContext.sql("select a.driverid,a.occurance,b.totmiles from geolocation_temp2 a,drivermileage_temp1 b where a.driverid=b.driverid")
%spark2
joined.createOrReplaceTempView("joined")
hiveContext.sql("show tables").show()

Obliczanie WSPÓŁCZYNNIKA RYZYKA (RISK_FACTOR) DLA KIEROWCY:
%spark2
val risk_factor_spark = hiveContext.sql("select driverid, occurance, totmiles, totmiles/occurance riskfactor from joined")

%spark2
risk_factor_spark.createOrReplaceTempView("risk_factor_spark")
hiveContext.sql("show tables").show()

DDL:
%spark2
hiveContext.sql("create table finalresults( driverid String, occurance bigint, totmiles bigint, riskfactor double) stored as orc").toDF()
hiveContext.sql("show tables").show()

%spark2
risk_factor_spark.write.format("orc").save("risk_factor_spark")


%spark2
hiveContext.sql("load data inpath 'risk_factor_spark' into table finalresults")


%spark
hiveContext.sql("create table riskfactor45 as select * from finalresults").toDF()
